---
layout: post
title: "Ustage Day 3"
categories: boostcamp
tags: main
comments: true
---
기본적인 통계학과 베이즈 통계학에 대한 내용 CNN, RNN까지 설명하도록 한다.

**부스트 캠프 3일차 학습 요약**
- **행사** : 피어세션이 피어(peer)씁니다~
- **강의** : 통계학 맛보기, 베이즈 통계학 맛보기, CNN 첫걸음, RNN 첫걸음
- **피어 세션**

## 목차
- [1. 통계학 맛보기](#1-통계학-맛보기)
- [2. 베이즈 통계학 맛보기](#2-베이즈-통계학-맛보기)
- [3. CNN 첫걸음](#3-CNN-첫걸음)
- [4. RNN 첫걸음](#4-RNN-첫걸음)
- [5. 피어 세션](#5-피어-세션)
- [6. 3일차 후기](#6-3일차-후기)
- [7. 해야할 일](#7-해야할-일)

## 1. 통계학 맛보기
### 1-1. 모수가 뭐에요?
- 통계적 모델링은 적절한 가정 위에서 확률분포를 추정하는 것이 목표이며, 기계학습과 통계학이 공통적으로 추구하는 목표이다.
- 한정된 데이터만 관찰해서 모집단의 분포를 정확히 알아내는 것은 불가능하므로 근사적으로 확률분포를 추정할 수밖에 없다.
- 예측 모형의 목적은 분포를 정확히 맞추는 것보다는 데이터와 추정 방법의 불확실성을 고려해서 위험을 최소화하는 것이다.
- 모수적 방법 : 데이터가 특정 확률분포를 따른다고 가정한 후에 그 분포를 결정하는 모수를 추정하는 방법
- 비모수적 방법 : 특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌는 것 -> 기계학습의 많은 방법론은 비모수 방법론에 속한다.
- 특히, 비모수라는 것은 모수가 없다는 것이 아니라 모수가 무한히 많거나 모수의 개수가 데이터에 따라서 바뀌는 경우를 말한다.

### 1-2. 확률분포 가정 예제
- 데이터가 2개의 값만을 가짐 -> 베르누이 분포
- 데이터가 n개의 이산적인 값 -> Categori 분포
- 데이터가 [0,1] 사이에서 값을 가짐 -> beta 분포
- 데이터가 0이상의 값을 가지는 경우 -> 감마분포, 로그정규분포 등등
- 데이터가 실수 전체에서 값을 가지는 경우 -> 정규분포, 라플라스분포 등등
- **Note :** 위에서 언급한 것처럼 데이터에 따라 따르는 분포가 어느 정도 정해져 있지만, 기계적으로 확률분포를 가정해서는 안되며 **데이터를 생성하는 원리**를 먼저 고려하는 것이 원칙이다.
- 각 분포마다 검정하는 방법들이 있으므로 모수를 추정한 후 반드시 검정을 진행해야 한다.

### 1-3. 데이터로 모수 추정
- 데이터의 확률분포를 가정했다면 모수를 추정할 수 있다.
- 정규분포의 모수는 평균과 분산이 존재하며 이를 추정하는 통계량은 다음과 같다.
![정규분포 모수 추정 통계량](https://user-images.githubusercontent.com/53552847/128302464-10b8c5a5-60c1-42e0-8989-0a58b9583222.PNG)
- 표본분산을 구할 때 `N-1`로 나누는 것은 Unbiased Estimator를 구하기 위해서 이다.
- 표본평균의 기대값은 모집단의 푱균과 같고, 표본분산의 기대값은 모집단의 분산과 같을 것이라고 기대한다.
- 불편추정량이란, 기대값을 취했을 때 원래 모집단의 통계치와 일치시키는 것을 유도하기 우해 사용되는 추정량이다.
- 통계량의 확률분포를 표집분포(Sampling Distribution)이라고 하고, 표본분포(Sample Distribution)과 다른 개념이다. 표본평균, 표본분산의 확률분포를 표집분포라고 한다.
- 표본평균의 표집분포는 중심극한정리에 의해 N이 커질수록 정규분포 N($$\mu$$, $$\sigma^2$$/N)을 따른다.

### 1-4. 최대가능도 추정법
- 표본평균이나 표본분산은 중요한 통계량이지만 확률분포마다 사용하는 모수가 다르므로 적절한 통계량이 달라진다.
- 이론적으로 가장 가능성이 높은 모술르 추정하는 방법 중 하나는 최대가능도 추정법(MLE : Maximum Likelyhood Estimation)이다.
![우도함수](https://user-images.githubusercontent.com/53552847/128303410-a06e920a-faae-4903-8566-ddcaba93a276.PNG)
- 우도함수는 모수 $$\theta$$ 를 따르는 분포가 x를 관찰할 가능성을 뜻하지만 확률로 해석하면 안된다.
- 데이터 집합 X가 독립적으로 추출되었을 경우 로그가능도를 최적화한다. (X의 각 행벡터가 독립적으로 추출될 경우)

### 1-5. 왜 로그가능도를 사용하는가?
- 로그가능도를 최적화하는 모수 $$\theta$$는 가능도를 최적화하는 MLE가 된다.
- 데이터가 엄청나게 클 경우 컴퓨터의 정확도로 일반적인 가능도를 계산하는 것은 불가능하다.
- 데이터가 독립일 경우, 가능도의 곱셈을 로그가능도의 덧셈으로 바꿀 수 있기 때문에 연산량을 줄일 수 있고 컴퓨터의 연산 역시 가능해진다.
- 경사하강법을 활용해 최적화하는 경우, 로그가능도는 연산량은 $$O(n)$$으로 훨씬 감소하게 된다.
- 대게의 Loss Function의 경우 경사하강법을 사용하므로 음의 로그가능도 (Negative Log Likelyhood)를 최적화하게 된다.
- 즉, 최적화 관점에서 굉장히 중요한 이유로 사용한다.
- **로그가능도를 각각의 파라미터로 미분하고 그 값을 0으로 만드는 파라미터의 값이 최종 MLE가 된다.**
- 최대가능도 추정법으로 구한 분산의 경우 불편추정량을 보장하지 않기 때문에 기존의 분산과 달리 n으로 나누어준다. 하지만, MLE의 경우 Consistence는 보장할 수 있다.

### 1-6. 카테고리 분포에서의 최대가능도 추정법
- 카테고리 분포는 평균과 분산과 같은 모수가 아니며 각 차원에서 어떤 값이 0 또는 1이 될 확률을 나타내는 모수이다.
- 카테고리 분포에서의 MLE 추정은 곧바로 미분하는 것이 아니라 목적식에 제약식을 정리해서 라그랑주 승수법을 활용해 최적화 문제를 해결한다.
- 최종 정리된 식에서 각 파라미터 p, $$\lambda$$에 대한 미분을 통해 MLE를 구해주게 된다.

### 1-7. 딥러닝에서 최대가능도 추정법
- 최대가능도 추정법을 이용해서 기계학습 모델을 학습할 수 있다.
- 딥러닝 모델의 가중치를 $$\theta$$ = ($$W_i$$, b)라고 할 때, 분류문제에서 Softmax 벡터는 카테고리분포의 모수 (p1, ..., pk)를 모델링한다.
- 원-핫벡터로 표현한 정답레이블 y를 관찰데이터로 이용해 확률분포인 Softmax 벡터의 로그가능도를 최적화할 수 있다.
- 다음은 Softmax 벡터를 활용하여 MLE를 추정한 예이다.
![소프트맥스 MLE 추정](https://user-images.githubusercontent.com/53552847/128305119-d4a38484-8f90-42b7-874c-2dcfee31f12a.PNG)

### 1-8. 확률분포의 거리 구하기
- 기계학습에서 사용되는 손실함수들은 모델이 학습하는 확률분포와 데이터에서 관찰되는 확률분포의 거리를 통해 유도된다.
- 데이터 공간에 두 개의 확률분포 P(x), Q(x)가 있을 경우, 두 확률분포 사이의 거리를 게산할 때는 '총 변동 거리, 쿨백-라이블러 발산, 바슈타인 거리'와 같은 함수ㄹ들을 활용한다.

### 1-9. KL-Divergence
- KL-Divergence의 정의는 다음과 같다.
![쿨백-라이블러 발산의 정의](https://user-images.githubusercontent.com/53552847/128305593-e83774fb-69e3-4f1f-b8e9-4a9f08a514f4.PNG)
- KL-Divergence의 분해는 다음과 같다.
![쿨백-라이블러 분해](https://user-images.githubusercontent.com/53552847/128305665-bed31ecb-ca16-4506-b041-b486951c604b.PNG)
- 분류 문제에서 정답레이블을 P, 모델 예측을 Q라 두면 최대가능도 추정법은 KL-Divergence를 최소화하는 것과 같다.
- 두 개의 확률분포 사이의 거리를 최소화 시킨다라는 것은 주어진 데이터를 통해서 목적으로 하는 확률분포의 최적화된 모수를 구하는 것과 동일한 개념으로 기계학습의 원리가 데이터로부터 확률분포 사이의 거리를 최소화하는 것과 동일하다는 것으로 이해할 수 있다.

**NOTE :** 논문을 볼 경우, 사용되는 Loss Function 혹은 최적화 모형이 어떻게 나왔는지를 고민해보고 MLE라는 관점에서 굉장히 많이 유도되어있다는 것을 기억하고 통계학적인 방법론을 기반으로 기계학습 모형들이 학습을 하게 된다라는 것을 기억하자.

## 2. 베이즈 통계학 맛보기
- 베이즈 정리 : 모델의 모수를 추정할 때 사용한다.
- 데이터가 새로 추가될 때, 정보를 업데이트 하는 방식에 대해 이론적 기반을 소개한다.
- 오늘날 기계학습을 사용하는 예측 모형의 방법론에 굉장히 많이 사용되는 방법론이다.

### 2-1. 조건부 확률이란?
- 조건부 확률의 기본식은 다음과 같다.
![조건부확률 식](https://user-images.githubusercontent.com/53552847/128442366-7e92ebbb-b6b0-430b-b22f-eb3b0299f505.PNG)
- 조건부 확률 P(A|B)는 사건 B가 일어난 상황에서 사건 A가 발생할 확률을 의미한다.
- 베이즈 정리는 조건부 확률을 이용하여 정보를 갱신하는 방법을 알려준다.
- 다음은 조건부확률의 변형 식이다.
![조건부확률 변형](https://user-images.githubusercontent.com/53552847/128442437-d0956d71-424d-4ba4-9f86-cc803aa7e9aa.PNG)
- 위의 변형된 식으로부터 A라는 새로운 정보가 주어졌을 때 P(B)로부터 P(B|A)를 계산할 수 있도록 한다.

### 2-2. 베이즈 정리 예제
- Notation
    - $$P(\theta|D)$$ : 사후확률 ( 데이터를 관찰한 이후에 측정하는 확률 ).
    - $$P(\theta)$$ : 사전확률 ( 데이터가 주어지지 않은 상황에서 사전에 주어진 확률), 데이터를 분석하기 전 어떤 모수, 가설과 같은 타겟에 대하여 사전에 설정된 가정, 가설로부터 사전에 정해놓은 확률분포
    - $$P(D)$$ : Evidence, 데이터 전체의 분포
    - $$P(D|\theta)$$ : Likelihood, 현재 주어진 모수 또는 가정에서 이 데이턱 관찰될 확률을 계산한다.
- 용어($$P(\theta)$$ 가 사전확률을 의미할 때)
    - $$P(D|\theta^c)$$ : 오탐률 (False Alarm)
    - $$P(D|\theta)$$ : 민감도 (Recall)
    - $$P(D^c |\theta^c)$$ : 특이도
- 흔히, False Alarm을 희생하면서 False Negative를 줄이기 위해 노력한다.
- 사전확률을 모를 때, 임의로 설정할 수 있지만 이 경우, 베이즈 통계학에서의 분석 효과의 신뢰도가 굉장히 떨어질 수 있으므로 상당히 주의를 해야하낟.

### 2-3. 베이즈 정리를 통한 정보의 갱신
- 새로운 데이터가 들어왔을 때 앞서 계산한 사후확률을 사전확률로 사용하여 갱신된 사후확률을 계산할 수 있다.
- 데이터 갱신에 대한 식은 다음과 같다.
![베이즈 정리 정보 업데이트](https://user-images.githubusercontent.com/53552847/128443063-9d83ee7a-e392-4308-a87a-b0aee6cef581.PNG)

### 2-4. 조건부확률을 이용한 인과관계?
- 조건부확률은 유용한 통계적 해석을 제공하지만 **인과관계를 추론할 때 함부로 사용해서는 안된다.**
- 아무리 데이터가 많아도 조건부 확률로만 인과관계를 추론하는 것은 불가능하다.
- **인과관계는 데이터 분포의 변화에 강건한 예측모형을 만들 때 필요하다.**
- 단, 인과관계만으로는 높은 예측 정확도를 담도하기 어렵다. 다만, 데이터 분포의 변화에 조금 강건한 예측 모형을 만들 수 있다. 즉, 새로운 시나리오가 들어온다 하더라도 예측의 큰 변화가 없다라는 것이다. (심슨의 역설)
- 조건부 확률로만 예측 모형을 만들었을 경우, 새로 유입되는 데이터의 분포가 바뀌게 되면 시나리오에 따라 예측확률이 크게 변할 수 있다.
- 인과관계를 알기 위해서는 중첩요인(Confounding Factor)의 효과를 제거하고 원인에 해당하는 변수만의 인과관계를 계산해야 한다.
- 다음 그림에서, Z를 중첩요인(Confounding Factor)라고 할 때, 이를 제거하지 않는 다면 가짜 연관성(Spurious Correlation)에 빠질 수 있다.
![인과관계](https://user-images.githubusercontent.com/53552847/128443452-013c79eb-ef42-477f-84ed-8d7924ba84b1.PNG)
- 예를 들어, 키가 커감에 따라 지능이 발달한다는 것은 높은 인과관계의 결과가 도출되는 데, 이 때 키가 커가는 것은 연령에 따라 증가하고, 연령에 다라 지능이 발달되기 때문에 이러한 잘못된 결과가 도출되는 것이다.
- 인과관계를 활용한 확률은 다음의 그림(심슨 역설)으로부터 구할 수 있다.
![Spurious Correlation](https://user-images.githubusercontent.com/53552847/128443769-326b7454-13f5-4972-ac68-5c5f2c70ea11.PNG)

![a인과관계 식](https://user-images.githubusercontent.com/53552847/128443853-17298446-4bbd-44d7-b2fe-9501d5f6f001.PNG)

![b인과관계 식](https://user-images.githubusercontent.com/53552847/128443861-2beffcb0-dc54-42cc-8f7e-65a72229c7e5.PNG)

## 3. CNN 첫걸음
### 3-1. Convolution 연산 이해하기
- 지금까지 배운 MLP는 각 뉴런들이 선형모델과 활성함수로 모두 연결된 구조였다.(Fully Connected)
- Convolution 연산은 Fully Connected 구조와 달리 **Kernel을 입력벡터 상에서 움직여 가면서 선형모델과 합성함수가 적용되는 구조이다.**
- 입력벡터 x에서 역시 kernel의 크기만큼만 움직여 가면서 사용한다.
- Kernel을 사용한 Convolution 연산 역시 활성함수가 없으면 선형변환에 속한다.
- 가중치 행이 위치에 따라 따로 존재하는 것이 아니라 Kernel_size가 그대로 적용되기 때문에(Kerner 속 가중치는 고정) Parameter_size를 굉장히 많이 줄일 수 있다.
- **Convolution 연산의 수학적인 의미는 신호를 kernel를 이용해서 국소적으로 증폭 또는 감소시켜 정보를 추출 또는 필터링하는 것이다.**
- 엄밀히 말하면 Cross Correlation 연산(-연산)이다. 왜냐하면 역사적으로 Convolution 이라고 불러왔고 이렇게 불렀던 이유는 전체공간에서 +, -가 중요하지 않아서인데, 컴퓨터에서 사용하려면 +, -사이의 차이가 크기 때문에 실제로는 Cross Correlation 연산이라고 할 수 있다.

### 3-2. 다양한 차원에서의 Convolution
- Convolution 연산은 1차원 뿐만 아니라 다양한 차원에서의 계산이 가능하다.
- 데이터의 성격에 따라 사용하는 커널이 달라진다. 기본적인 식은 다음과 같다.
![합성곱 식](https://user-images.githubusercontent.com/53552847/128307694-afffefa8-2f6f-4af4-886f-d520ccdef103.PNG)
- Kernel이 위치에 따라 바뀌지 않는다는 것을 꼭 기억하자.

### 3-3. 2D Convolution 연산 이해하기 - 흔히 영상처리의 차원이다(2D, 3D)
- 2D Conv 연산은 Kernel(다시 한번 언급하지만 Kernel은 변하지 않는다.)을 입력벡터 상에서 움직여가면서 선형모델과 합성함수가 적용되는 구조이다.
- 입력, 커널, 출력의 크기를 각각 H, K, O라고 할 때 출력의 크기는 'O = H - K + 1'이고, 이를 통해서 출력의 크기를 파악할 수 있다. (이후에 stride에 따라서 식이 변한다.)
- 3D의 경우 2차원 Convolution을 채널 개수만큼 kernel을 만들어 적용한다고 생각하면 된다.
- 계산 과정은 텐서를 직육면체 블록으로 이해할 수 있으며 최종 Output은 1개의 채널이 출력된다.
- 출력의 채널을 여러 개 만들기 위해서는 Kernel의 개수를 여러개 만들어주면 된다. 커널을 $$O_c$$개 사용하면 출력의 채널이 $$O_c$$개로 변한다.

### 3-4. Convolution 연산의 역전파 이해화기
- Convolution 연산은 커널이 모든 입력데이터에 공통으로 적용되기 때문에 역전파를 계산할 때도 Convolution 연산이 나오게 된다. 
- Convolution 연산의 역전파식은 다음과 같다.
![Convolution 역전파 식](https://user-images.githubusercontent.com/53552847/128308543-54b1d192-22a3-42b9-99b4-d94e84564024.PNG)
- Convolution의 역전파 식은 연속이든 이산이든 상관없이 성립한다.
- 출력값의 위치에 미분값이 전달되었다고 할 때, 역전파 단계에서 이 미분값들이 다시 Kernel을 통해 그래디언트가 전달된다. 그러므로 다음과 같은 그림으로 이해할 수 있다.
![Conv 2D 역전파 그림](https://user-images.githubusercontent.com/53552847/128308782-7862eb29-fd6a-4068-a5b4-7aaf03990819.PNG)
- 각각의 Kernel들의 Gradient가 전달되는 것은 $$W_1$$에 의해 $$\delta$$3가 생성되었으므로 $$w_1$$의 Gradient는 $$\delta$$3와 $$x_3$$의 곱이 된다.

## 4. RNN 
### 4-1. 시퀀스 데이터 이해하기
- 소리, 문자열, 주가 등의 데이터를 시퀀스 데이터로 분류한다.
- 순차적으로 들어오는 데이터를 의미한다.
- 시계열 데이터는 시간 순서에 따라 나열된 데이터로 시퀀스 데이터에 속한다.
- 독립동등분포(i.i.d) 가정을 위배하기 때문에 순서를 바꾸거나 과거 정보에 손실이 발생하면 데이터의 확률분포도 바뀌게 된다.
- 과거 정보 또는 앞뒤 맥락 없이 미래를 예측하거나 문장을 완성하는 건 불가능 하다.

### 4-2. 시퀀스 데이터를 어떻게 다루나요?
- 이전 시퀀스의 정보를 가지고 앞으로 발생할 데이터의 확률분포를 다루기 위해 조건부확률을 이용할 수 있다.
- 베이즈 법칙을 이용해 결합확률분포를 다음과 같이 구할 수 있다.
![시퀀스 베이즈 법칙](https://user-images.githubusercontent.com/53552847/128444268-49b670dc-1567-4e46-ac4a-7e7adf7f2a11.PNG)
- 시퀀스 데이터를 분석할 때 모든 과거 정보들이 필요한 것은 아니다.
- 필요에 따라서 과거의 데이터를 어떻게 활용할 지에 대해서도 깊이 있게 고민해야한다. 더불어, 모델링의 방법에 따라서 필요한 데이터가 달라질 수 있다는 것도 고려하고 있어야 한다.
- 시퀀스 데이터를 다루기 위해서는 길이가 가변적인 데이터를 다룰 수 있는 모델이 필요하다.
- 고전된 길이 $$\tau$$만큼의 시퀀스만을 사용할 경우 $$AR(\tau)$$ (AutoRegressive Model)인 자귀회귀모델이라고 한다. 이 경우에, 사전에 $$\tau$$를 정해야 하며 Parameter로서 $$\tau$$를 정의하는 것은 많은 사전 지식을 필요로 한다.
- 바로 이전 정보를 제외한 나머지 정보들을 $$H_t$$라는 잠재변수로 인코딩해서 활용하는 모델을 잠재AR 모델이라고 한다.
- 잠재 AR 모델에서 과거의 정보들의 잠재변수 설정을 어떻게 인코딩할 것인지에 대한 문제를 해결하고자 등장한 모델이 RNN 이다.
- 잠재 AR 모델에서 $$H_t$$를 신겨망을 통해 반복해서 사용함으로서 시퀀스 데이터의 패턴을 학습하는 모델이 RNN 이다.

### 4-3. RNN 이해 및 BPTT(BackPropagation Through Time)
- 가장 기본적인 RNN은 MLP와 유사하다.
- RNN은 이전 순서의 잠재변수와 현재의 입력을 활용하여 모델링한다.
- 가중치 행렬은 t(시간)에 따라 변하지 않는 행렬이다.
![RNN 그림 및 식](https://user-images.githubusercontent.com/53552847/128445417-82f671f0-91f0-464b-99cf-f7f1a9855fef.PNG)
- BPTT(BackPropagation Through Time)을 통해 RNN의 가중치 행렬의 미분을 계산해보면 아래와 같이 계산된다.
![BPTT](https://user-images.githubusercontent.com/53552847/128445598-2859e76f-0945-4d2b-802b-0222bdc83378.PNG)
- 마지막 항에서 미분의 곱으로 이루어진 항이 있는데, 이 Product Term이 시퀀스 길이가 길어질수록 불안정해지기 쉽다. 이 Term이 1보다 크면 엄청나게 커질 수 있고, 1보다 작으면 미분값이 엄청나게 작아질 수 있기 때문이다.(Gradient Exploding, Grading Vanishing)

### 4-4. 기울기 소실의 해결책(Solution of Gradient Vanishing)
- 시퀀스 길이가 길어지는 경우 BPTT를 통한 역전파 알고리즘의 계산이 불안정해지므로 길이를 끊는 것이 필요하다. 이 때, Truncated BPTT를 사용하여 어느 정도 해결할 수 있다.
- Truncated BPTT : 미래의 정보들 중에서 몇 개는 Gradient를 끊고 오로지 과거에 해당하는 몇 개의 블럭을 나눠서 BackPropagation 연산을 진행하는 과정을 의미한다.
- 모든 관찰된 예측 순간에 대하여 BPTT를 적용하게 되면 Gradient를 전부 곱해주는 형태가 되므로 굉장히 불안정해진다. 특히, Gradient가 0으로 줄어들 때 굉장히 큰 문제가 된다. 왜냐하면, 과거로 가면서 Gradient가 점점 0으로 줄어들게 되면 과거 시점에 대하여 이전 시점에 대한 예측 모델에 대한 반영이 쉽지 않기 때문이다. 즉, 과거정보를 유실할 확률이 높다.

### 4-5. 기울기 소실의 해결책은?
- 시퀀스 길이가 길어지는 경우 BPTT를 통해 역전파 알고리즘의 계산이 불안정해지므로 Truncated BPTT를 활용하여 좀 더 안정하게 만들어준다.
- LSTM과 GRU와 같은 모데을 활용한다. (Vanila RNN은 활용하기 힘들다.)

## 5. 피어 세션
### 5-1. 이전 질문 리뷰
- SGD의 연산량이 GD보다 연산량이 더 많아서 덜 효율적인가?
  - 시간복잡도의 경우 Iteration 당 시간복잡도를 기준으로 설정
  - Iteration 당 시간복잡도의 경우 다음과 같다.
    - GD : O(total_data $$d^2$$)
    - SGD : O(1 * $$d^2$$)
    - MSGD : O(batch_size * $$d^2**$$)
   
### 5-2. 금일 질문 목록
- 왜 Relu가 비선형 함수인가?
  - 선형함수의 특징
    - 선형그래프의 모양을 띄고있어야 한다.
    - 동차성 : $$f(ax) = af(x)$$를 만족해야한다.
    - 가산성 : $$f(x_1 + x_2)$$ = $$f(x_1)$$ + $$f(x_2)$$를 만족해야한다.

- sigmoid와 relu의 차이
    - sigmoid의 경우 극값으로 갈수록 gradient vanishing 현상을 유발할 수 있다.
    - relu의 경우 양수일 때 미분값이 항상 1이므로 gradient vanishing 현상을 방지할 수 있다.

- KL-Divergence
    - 분산이 다를 때 사용한다.

## 6. 3일차 후기
강의뿐만 아니라 과제의 난이도 역시 지수함수 그래프형식으로 점점 올라가는 것 같다....

할 일이 생각보다 많고 정리할 내용 스스로 학습해야할 내용이 많아서 팀원들과의 협업이 절실하다는 것을 깨닫게 되었고 쉬는 시간이 뭔지 점점 잊어가는 중이다 ㅜㅜ  
제발

## 7. 해야할 일
- 인과관계를 활용한 확률 구하기
- Causality란?
- RNN에서 가중치 행렬은 t(시간)에 따라 변하지 않는 행렬이다. ?? 무슨 의미?
